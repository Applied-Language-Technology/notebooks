{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding linguistic patterns using spaCy\n",
    "\n",
    "This section teaches you to find linguistic patterns using spaCy, a natural language processing library for Python.\n",
    "\n",
    "If you are unfamiliar with the linguistic annotations produced by spaCy or need to refresh your memory, revisit [Part II](../part_ii/03_basic_nlp.ipynb) before working through this section.\n",
    "\n",
    "After reading this section, you should:\n",
    "\n",
    " - know how to search for patterns among Tokens and their sequences\n",
    " - know how to search for patterns among morphological features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding patterns using spaCy Matchers\n",
    "\n",
    "Linguistic annotations, such as part-of-speech tags, syntactic dependencies and morphological features, help impose structure on written language. Crucially, linguistic annotations allow searching for structural patterns instead of individual words or phrases. This allows defining search patterns in a flexible way.\n",
    "\n",
    "In the spaCy library, the capability for pattern search is provided by various components named Matchers.\n",
    "\n",
    "spaCy provides three types of Matchers:\n",
    "\n",
    "1. A [Matcher](https://spacy.io/api/matcher), which allows defining rules that search for particular **words or phrases** by examining *Token* attributes.  \n",
    "2. A [DependencyMatcher](https://spacy.io/api/dependencymatcher), which allows searching parse trees for **syntactic patterns**.\n",
    "3. A [PhraseMatcher](https://spacy.io/api/phrasematcher), a fast method for matching spaCy *Doc* objects to *Doc* objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding words or phrases\n",
    "\n",
    "To get started with the *Matcher*, let's import the spaCy library and load a small language model for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library into Python\n",
    "import spacy\n",
    "\n",
    "# Load a small language model for English; assign the result under 'nlp'\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have some data to work with, let's load some text from a Wikipedia article.\n",
    "\n",
    "To do so, we use Python's `open()` function to open the file for reading, providing the `file`, `mode` and `encoding` arguments, as instructed in [Part II](../part_ii/01_basic_text_processing.ipynb#Loading-plain-text-files-into-Python).\n",
    "\n",
    "We then call the `read()` method to read the file contents, and store the result under the variable `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the open() function to open the file for reading, followed by the\n",
    "# read() method to read the contents of the file.\n",
    "text = open(file='data/occupy.txt', mode='r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a Python string object that contains the article in plain text, which is available under the variable `text`.\n",
    "\n",
    "Next, we then feed this object to the language model under the variable `nlp` as instructed in [Part II](../part_ii/03_basic_nlp.ipynb#Performing-basic-NLP-tasks-using-spaCy).\n",
    "\n",
    "We also use Python's `len()` function to count the number of words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed the string object to the language model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Use the len() function to check length of the Doc object to count \n",
    "# how many Tokens are contained within.\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a spaCy *Doc* object with nearly 15 000 *Tokens*, we can continue to import the *Matcher* class from the `matcher` submodule of spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher class\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the *Matcher* class from spaCy's `matcher` submodule allows creating *Matcher* objects.\n",
    "\n",
    "When creating a *Matcher* object, you must provide the vocabulary of the language model used for finding matches to the *Matcher* object.\n",
    "\n",
    "The reason for this is really rather simple: if you want to search for patterns in some language, you need to know its vocabulary first.\n",
    "\n",
    "The vocabulary of a model is stored in a [*Vocab*](https://spacy.io/api/vocab) object. The *Vocab* object can be found under the attribute `vocab` of a spaCy *Language* object, which was introduced in [Part II](../part_ii/03_basic_nlp.ipynb#Performing-basic-NLP-tasks-using-spaCy).\n",
    "\n",
    "In this case, we have the *Language* object that contains a small language model for English stored under the variable `nlp`, which means we can access its *Vocab* object by calling `nlp.vocab`.\n",
    "\n",
    "We then call the *Matcher* **class** and provide the vocabulary under `nlp.vocab` to the `vocab` argument to create a *Matcher* object. We store the resulting object under the variable `matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.matcher.matcher.Matcher at 0x14ee96cc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Matcher and provide model vocabulary; assign result under the variable 'matcher'\n",
    "matcher = Matcher(vocab=nlp.vocab)\n",
    "\n",
    "# Call the variable to examine the object\n",
    "matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Matcher* object is now ready to store the patterns that we want to search for.\n",
    "\n",
    "These patterns, or more specifically, *pattern rules*, are created using a [specific format](https://spacy.io/api/matcher#patterns) defined in spaCy.\n",
    "\n",
    "Each pattern consists of a Python list, which is populated by Python dictionaries. \n",
    "\n",
    "Each dictionary describes the pattern for matching a single spaCy *Token*. \n",
    "\n",
    "If you wish to match a sequence of *Tokens*, you must define multiple dictionaries within a single list, whose order follows that of the pattern to be matched.\n",
    "\n",
    "Let's start by defining a simple pattern for matching sequences of pronouns and verbs, which we store under the variable `pronoun_verb`.\n",
    "\n",
    "This pattern consists of a list, as marked by the surrounding brackets `[]`, which contains two dictionaries, marked by curly braces `{}` and separated by a comma. The key and value pairs in a dictionary are separated by a colon.\n",
    "\n",
    " - The dictionary key determines which *Token* attribute should be searched for matches. The attributes supported by the *Matcher* can be found [here](https://spacy.io/api/matcher#patterns).\n",
    "\n",
    " - The value under the dictionary key determines the specific value for the attribute.\n",
    "\n",
    "In this case, we define a pattern that searches for a sequence of two coarse part-of-speech tags (`POS`), which were introduced in [Part II](../part_ii/03_basic_nlp.ipynb#Part-of-speech-tagging), namely pronouns (`PRON`) and verbs (`VERB`).\n",
    "\n",
    "Note that both keys and values must be provided in uppercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with nested dictionaries that contains the pattern to be matched\n",
    "pronoun_verb = [{'POS': 'PRON'}, {'POS': 'VERB'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the pattern using a list and dictionaries, we can add it to the *Matcher* object under the variable `matcher`.\n",
    "\n",
    "This can be achieved using `add()` method, which requires two inputs:\n",
    "\n",
    " 1. A Python string object that defines a name for the pattern. This is simply for purposes of identification.\n",
    " 2. A list containing the pattern(s) to be searched for. A single rule for matching patterns can contain multiple patterns, hence the input must be a *list of lists*, e.g. `[pattern_1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher under the name 'pronoun+verb'\n",
    "matcher.add(\"pronoun+verb\", patterns=[pronoun_verb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for matches the *Doc* object stored under the variable `doc`, we feed the *Doc* object to the *Matcher* and store the result under the variable `result`.\n",
    "\n",
    "We also set the optional argument `as_spans` to `True`, which instructs spaCy to return the results as *Span* objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[It aimed,\n",
       " It formed,\n",
       " it organizes,\n",
       " who designed,\n",
       " He wrote,\n",
       " They promoted,\n",
       " It refers,\n",
       " they saw,\n",
       " they argued,\n",
       " they called,\n",
       " it takes,\n",
       " they called,\n",
       " who comment,\n",
       " them using,\n",
       " they belong,\n",
       " himself warned,\n",
       " he said,\n",
       " they think,\n",
       " them gain,\n",
       " they wished,\n",
       " they blamed,\n",
       " I support,\n",
       " I saw,\n",
       " It showed,\n",
       " who gave,\n",
       " they refused,\n",
       " they saw,\n",
       " who caused,\n",
       " We are,\n",
       " who sought,\n",
       " who were,\n",
       " who were,\n",
       " who made,\n",
       " who criticized,\n",
       " it returned,\n",
       " its proposed,\n",
       " They received,\n",
       " there have,\n",
       " it came,\n",
       " it gained,\n",
       " He claimed,\n",
       " they presented,\n",
       " they call,\n",
       " It consists,\n",
       " there were,\n",
       " there was,\n",
       " What started,\n",
       " it is,\n",
       " they began,\n",
       " they perceived,\n",
       " they say,\n",
       " We agree,\n",
       " we see,\n",
       " it's,\n",
       " who are,\n",
       " who say,\n",
       " what's,\n",
       " they do,\n",
       " they reflect,\n",
       " He mentioned,\n",
       " We regard,\n",
       " who participated,\n",
       " he wrote,\n",
       " we have,\n",
       " who dislike,\n",
       " they employ,\n",
       " they have,\n",
       " there is,\n",
       " it stall,\n",
       " who emerged,\n",
       " It pushes,\n",
       " who called]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the Matcher to the Doc object under 'doc'; provide the argument\n",
    "# 'as_spans' and set its value to True to get Spans as output\n",
    "result = matcher(doc, as_spans=True)\n",
    "\n",
    "# Call the variable to examine the output\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of spaCy *Span* objects that match the requested pattern. Let's examine the first object in the list of matches in greater detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It aimed"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Span* object has various useful attributes, including `start` and `end`. These attributes contain the indices that indicate where in the *Doc* object the *Span* starts and finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 38)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].start, result[0].end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful attribute is `label`, which contains the name that we gave to the pattern. Let's take a closer look at this attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12298179334642351811"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value stored under the `label` attribute is actually a spaCy [*Lexeme*](https://spacy.io/api/lexeme) object that corresponds to an entry in the language model's vocabulary. \n",
    "\n",
    "This *Lexeme* contains the name that we gave to the search pattern above, namely `pronoun+verb`.\n",
    "\n",
    "We can easily verify this by fetching this *Lexeme* from the *Vocab* object under `nlp.vocab` and examining its `text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun+verb'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[12298179334642351811].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information under the `label` attribute is useful for disambiguating between patterns, especially if the same *Matcher* object contains multiple different patterns, as we will see shortly below.\n",
    "\n",
    "Looking at the matches above, the pattern we defined is quite restrictive, as the pronoun and the verb must follow each other.\n",
    "\n",
    "We cannot, for example, match patterns where the verb is preceded by auxiliary verbs.\n",
    "\n",
    "spaCy allows increasing the flexibility of pattern rules using operators. These operators are defined by adding the key `OP` to the dictionary that defines a pattern for a single *Token*. spaCy supports the following operators:\n",
    "\n",
    " - `!`: Negate the pattern; the pattern can occur exactly zero times.\n",
    " - `?`: Make the pattern optional; the pattern may occur zero or one times.\n",
    " - `+`: Require the pattern to occur one or more times.\n",
    " - `*`: Allow the pattern to match zero or more times.\n",
    "\n",
    "Let's explore the use of operators by defining another pattern rule, which extends the scope of our *Matcher*.\n",
    "\n",
    "To do so, we define another pattern for a *Token* between the pronoun and the verb. This *Token* must have the coarse part-of-speech tag `AUX`, which indicates an auxiliary verb. \n",
    "\n",
    "In addition, we add another key and value pair to the dictionary for this *Token*, which contains the key `OP` with the value `+`. This means that the *Token* corresponding to an auxiliary verb must occur *one or more times*.\n",
    "\n",
    "We store the resulting list with nested dictionaries under the variable `pronoun_aux_verb`, and add the pattern to the existing *Matcher* object stored under the variable `matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with nested dictionaries that contains the pattern to be matched\n",
    "pronoun_aux_verb = [{'POS': 'PRON'}, {'POS': 'AUX', 'OP': '+'}, {'POS': 'VERB'}]\n",
    "\n",
    "# Add the pattern to the matcher under the name 'pronoun+aux+verb'\n",
    "matcher.add('pronoun+aux+verb', patterns=[pronoun_aux_verb])\n",
    "\n",
    "# Apply the Matcher to the Doc object under 'doc'; provide the argument 'as_spans'\n",
    "# and set its value to True to get Spans as output. Overwrite previous matches by\n",
    "# storing the result under the variable 'results'.\n",
    "results = matcher(doc, as_spans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as above, the *Matcher* returns a list of spaCy *Span* objects.\n",
    "\n",
    "Let's loop over each item in the list `results`. We use the variable `result` to refer to the *Span* objects in the list, which contain our matches.\n",
    "\n",
    "We first retrieve the *Lexeme* object stored under `result.label`, which we map to the language model's *Vocabulary* under `nlp.vocab`. \n",
    "\n",
    "As we learned above, this *Lexeme* corresponds to the name that we gave to the pattern rule, whose human-readable form can be found under the attribute `text`.\n",
    "\n",
    "We then print a tabulator character to insert some space between the name of the pattern and the *Span* object containing the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronoun+verb \t It aimed\n",
      "pronoun+verb \t It formed\n",
      "pronoun+verb \t it organizes\n",
      "pronoun+verb \t who designed\n",
      "pronoun+verb \t He wrote\n",
      "pronoun+verb \t They promoted\n",
      "pronoun+verb \t It refers\n",
      "pronoun+aux+verb \t they did have\n",
      "pronoun+verb \t they saw\n",
      "pronoun+verb \t they argued\n",
      "pronoun+verb \t they called\n",
      "pronoun+verb \t it takes\n",
      "pronoun+aux+verb \t they were working\n",
      "pronoun+aux+verb \t there had been\n",
      "pronoun+aux+verb \t who had lost\n",
      "pronoun+verb \t they called\n",
      "pronoun+aux+verb \t themselves be informed\n",
      "pronoun+verb \t who comment\n",
      "pronoun+verb \t them using\n",
      "pronoun+aux+verb \t anyone can join\n",
      "pronoun+aux+verb \t what is called\n",
      "pronoun+verb \t they belong\n",
      "pronoun+verb \t himself warned\n",
      "pronoun+verb \t he said\n",
      "pronoun+verb \t they think\n",
      "pronoun+aux+verb \t they will change\n",
      "pronoun+aux+verb \t it can help\n",
      "pronoun+verb \t them gain\n",
      "pronoun+verb \t they wished\n",
      "pronoun+verb \t they blamed\n",
      "pronoun+aux+verb \t It was organized\n",
      "pronoun+verb \t I support\n",
      "pronoun+verb \t I saw\n",
      "pronoun+verb \t It showed\n",
      "pronoun+aux+verb \t It was renamed\n",
      "pronoun+verb \t who gave\n",
      "pronoun+aux+verb \t they may want\n",
      "pronoun+verb \t they refused\n",
      "pronoun+aux+verb \t who were arrested\n",
      "pronoun+verb \t they saw\n",
      "pronoun+verb \t who caused\n",
      "pronoun+verb \t We are\n",
      "pronoun+verb \t who sought\n",
      "pronoun+aux+verb \t It was reported\n",
      "pronoun+aux+verb \t it may be\n",
      "pronoun+aux+verb \t they were beginning\n",
      "pronoun+verb \t who were\n",
      "pronoun+aux+verb \t they had received\n",
      "pronoun+aux+verb \t he would bring\n",
      "pronoun+verb \t who were\n",
      "pronoun+verb \t who made\n",
      "pronoun+aux+verb \t they're obligated\n",
      "pronoun+aux+verb \t who were detained\n",
      "pronoun+verb \t who criticized\n",
      "pronoun+verb \t it returned\n",
      "pronoun+verb \t its proposed\n",
      "pronoun+aux+verb \t there have been\n",
      "pronoun+verb \t They received\n",
      "pronoun+verb \t there have\n",
      "pronoun+aux+verb \t it was torn\n",
      "pronoun+aux+verb \t it has spread\n",
      "pronoun+aux+verb \t whom were left\n",
      "pronoun+verb \t it came\n",
      "pronoun+verb \t it gained\n",
      "pronoun+verb \t He claimed\n",
      "pronoun+verb \t they presented\n",
      "pronoun+verb \t they call\n",
      "pronoun+aux+verb \t it was reported\n",
      "pronoun+verb \t It consists\n",
      "pronoun+verb \t there were\n",
      "pronoun+verb \t there was\n",
      "pronoun+verb \t What started\n",
      "pronoun+verb \t it is\n",
      "pronoun+aux+verb \t who were occupying\n",
      "pronoun+aux+verb \t It was expected\n",
      "pronoun+aux+verb \t it was disbanded\n",
      "pronoun+aux+verb \t it was fenced\n",
      "pronoun+verb \t they began\n",
      "pronoun+verb \t they perceived\n",
      "pronoun+verb \t they say\n",
      "pronoun+verb \t We agree\n",
      "pronoun+verb \t we see\n",
      "pronoun+aux+verb \t There's growing\n",
      "pronoun+verb \t it's\n",
      "pronoun+aux+verb \t I can understand\n",
      "pronoun+verb \t who are\n",
      "pronoun+aux+verb \t it will grow\n",
      "pronoun+aux+verb \t it will bring\n",
      "pronoun+verb \t who say\n",
      "pronoun+aux+verb \t we can build\n",
      "pronoun+verb \t what's\n",
      "pronoun+verb \t they do\n",
      "pronoun+aux+verb \t they're penalized\n",
      "pronoun+verb \t they reflect\n",
      "pronoun+verb \t He mentioned\n",
      "pronoun+verb \t We regard\n",
      "pronoun+verb \t who participated\n",
      "pronoun+aux+verb \t they were removed\n",
      "pronoun+verb \t he wrote\n",
      "pronoun+verb \t we have\n",
      "pronoun+aux+verb \t they have been protesting\n",
      "pronoun+aux+verb \t they will have made\n",
      "pronoun+verb \t who dislike\n",
      "pronoun+verb \t they employ\n",
      "pronoun+verb \t they have\n",
      "pronoun+aux+verb \t it has cleared\n",
      "pronoun+aux+verb \t it would have\n",
      "pronoun+aux+verb \t what became known\n",
      "pronoun+verb \t there is\n",
      "pronoun+verb \t it stall\n",
      "pronoun+verb \t who emerged\n",
      "pronoun+verb \t It pushes\n",
      "pronoun+verb \t who called\n",
      "pronoun+aux+verb \t whom have observed\n",
      "pronoun+aux+verb \t who are running\n",
      "pronoun+aux+verb \t you're going\n"
     ]
    }
   ],
   "source": [
    "# Loop over each Span object in the list 'results'\n",
    "for result in results:\n",
    "    \n",
    "    # Print out the the name of the pattern rule, a tabulator character, and the matching Span\n",
    "    print(nlp.vocab[result.label].text, '\\t', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that the pattern we added to the *Matcher* matches patterns that contain one (e.g. \"we *can* build\") or more (e.g. \"they *have been* protesting\") auxiliaries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding morphological features\n",
    "\n",
    "As introduced in [Part II](../part_ii/03_basic_nlp.ipynb#Morphological-analysis), spaCy can also perform morphological analysis for individual *Tokens*, whose results are stored under the attribute `morph` of a *Token* object.\n",
    "\n",
    "The `morph` attribute contains a string object, in which each morphological feature is separated by a vertical bar `|`, as illustrated below.\n",
    "\n",
    "```\n",
    "We \t Case=Nom|Number=Plur|Person=1|PronType=Prs\n",
    "```\n",
    "\n",
    "As you can see, particular types of morphological features, e.g. *Case*, and their type, e.g. *Nom* (for the nominative case) are separated by equal signs `=`.\n",
    "\n",
    "Let's begin exploring how we can define pattern rules that match morphological features.\n",
    "\n",
    "To get started, we create a new *Matcher* object named `morph_matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Matcher and provide model vocabulary; assign result under the variable 'morph_matcher'\n",
    "morph_matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a new pattern with rules for two *Tokens*:\n",
    "\n",
    " 1. Tokens that have a fine-grained part-of-speech tag `NNP` (proper noun), which can occur one or more times (operator: `+`)\n",
    " 2. Tokens that have a coarse part-of-speech tag `VERB` and have precisely the following morphological features (`MORPH`): `Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin`\n",
    " \n",
    "We define the pattern using two dictionaries in a list, which we assign under the variable `propn_3rd_finite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with nested dictionaries that contains the pattern to be matched\n",
    "propn_3rd_finite = [{'TAG': 'NNP', 'OP': '+'},\n",
    "                    {'POS': 'VERB', 'MORPH': 'Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add the pattern to the newly-created *Matcher* stored under the variable `morph_matcher` using the `add()` method.\n",
    "\n",
    "We also provide the value `LONGEST` to the optional argument `greedy` for the `add()` method.\n",
    "\n",
    "The `greedy` argument filters the matches for *Tokens* that include operators such as `+` that search *greedily* for more than one match.\n",
    "\n",
    "By setting the value to `LONGEST`, spaCy returns the longest sequence of matches instead of returning every match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher under the name 'sing_3rd_pres_fin'\n",
    "morph_matcher.add('sing_3rd_pres_fin', patterns=[propn_3rd_finite], greedy='LONGEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply the *Matcher* to the data stored under the variable `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupy Wall Street uses\n",
      "Rolling Jubilee claims\n",
      "Noam Chomsky argues\n",
      "Rolling Jubilee reports\n",
      "Information Act requests\n",
      "Jodi Dean argues\n"
     ]
    }
   ],
   "source": [
    "# Apply the Matcher to the Doc object under 'doc'; provide the argument 'as_spans'\n",
    "# and set its value to True to get Spans as output. Overwrite previous matches by\n",
    "# storing the result under the variable 'results'.\n",
    "morph_results = morph_matcher(doc, as_spans=True)\n",
    "\n",
    "# Loop over each Span object in the list 'morph_results'\n",
    "for result in morph_results:\n",
    "\n",
    "    # Print result\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the matches are relatively few in number, because we defined that the verb should have quite specific morphological features.\n",
    "\n",
    "The question is, then, how can match just *some* morphological features?\n",
    "\n",
    "To loosen the criteria for morphological features by focusing on [tense](https://en.wikipedia.org/wiki/Grammatical_tense) only, we need to use a dictionary with the key `MORPH`, but instead of a string object, we provide a dictionary as the value.\n",
    "\n",
    "For this dictionary, we use the string `IS_SUPERSET` as the key. `IS_SUPERSET` is one of the attributes defined in the spaCy [pattern format](https://spacy.io/api/matcher#patterns).\n",
    "\n",
    "Before proceeding any further, let's unpack the logic behind `IS_SUPERSET` a bit: \n",
    "\n",
    "We can think of morphological features associated with a given Token as a [set](https://en.wikipedia.org/wiki/Set_(mathematics)). To exemplify, a set could consist of the following four items:\n",
    "\n",
    "```\n",
    "Number=Sing, Person=Three, Tense=Pres, VerbForm=Fin\n",
    "```\n",
    "\n",
    "If we would have *another set* with just one item, `Tense=Pres`, we could describe the relationship between the two sets by stating that the first set (with four items) is a superset of the second set (with one item).\n",
    "\n",
    "In other words, the larger (super)set contains the smaller (sub)set.\n",
    "\n",
    "This is also how matching using `IS_SUPERSET` works: spaCy retrieves the morphological features for a given *Token*, and examines whether these features are a superset of the features defined in the search pattern.\n",
    "\n",
    "The morphological features to be searched for are provided as a list of Python strings.\n",
    "\n",
    "These strings, in turn, define particular morphological features, e.g. `Tense=Past`, as defined in the [Universal Dependencies](https://universaldependencies.org/u/overview/morphology.html) schema for describing morphology.\n",
    "\n",
    "This list is then used as the value for the key `IS_SUPERSET`.\n",
    "\n",
    "Let's now proceed to search for verbs in the past tense and add them to the *Matcher* object under `morph_matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with nested dictionaries that contains the pattern to be matched\n",
    "past_tense = [{'TAG': 'NNP', 'OP': '+'},\n",
    "              {'POS': 'VERB', 'MORPH': {'IS_SUPERSET': ['Tense=Past']}}]\n",
    "\n",
    "# Add the pattern to the matcher under the name 'past_tense'\n",
    "morph_matcher.add('past_tense', patterns=[past_tense], greedy='LONGEST')\n",
    "\n",
    "# Apply the Matcher to the Doc object under 'doc'; provide the argument 'as_spans'\n",
    "# and set its value to True to get Spans as output. Overwrite previous matches by\n",
    "# storing the result under the variable 'results'.\n",
    "morph_results = morph_matcher(doc, as_spans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's loop over the results and print out the name of the pattern, the *Span* object containing the match, and the morphological features of the final *Token* in the match, which corresponds to the verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_tense \t Community Environmental Legal Defense Fund released \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Oakland Police Chief Howard Jordan expressed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t U.S. Vice President Al Gore called \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Los Angeles City Council became \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Judge Jed S. Rakoff sided \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Finance Minister Jim Flaherty expressed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Prime Minister Manmohan Singh described \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Supreme Leader Ayatollah Khamenei voiced \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Prime Minister Gordon Brown said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Anti-Defamation League stated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Wall Street endorsed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t New York Times reported \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Wall Street said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Lieutenant John Pike used \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Wall Street attempted \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Mayor Charlie Hales ordered \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Pietro al Laterano received \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Taksim Gezi Park developed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t International Press Institute commented \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t President Dilma Rousseff said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Edinburgh City Council set \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t President Barack Obama spoke \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t New York City sent \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t President Hugo Chávez condemned \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t American Dialect Society voted \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Manfred Steger called \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Cornel West described \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Huffington Post noted \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Kalle Lasn registered \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Democracy Village set \t Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "past_tense \t Naomi Wolf argued \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Judith Butler criticized \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Manuel Castells congratulated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Naomi Klein congratulated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t USA Today said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Anthony Barnett said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Kanye West justified \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Michael Moore tweeted \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t WikiLeaks Central began \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Alexa O'Brien modeled \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Richard Lambert suggested \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Shannon Bond found \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Washington Post reported \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Nigeria began \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t January Jonathan responded \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Hurricane Sandy hit \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Bernie Sanders protested \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Movement organized \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Kalamazoo began \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Sydney had \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Pirate Party participated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t United Nations controlled \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Berlin established \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t High Court ruled \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Irish Times described \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Seoul contained \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t South Korea overcame \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t M Movement drew \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Lancaster Police arrested \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Belfast initiated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Belfast took \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Coleraine took \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy Glasgow set \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Francis Fukuyama argued \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Richard Branson said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Jesse Jackson said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Daily Telegraph reported \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Financial Times argued \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Paul Mason said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Atlantic Magazine declared \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t England stated \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t California occupied \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Spain marked \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Anonymous encouraged \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t U.S. saw \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Adbusters said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Wolf argued \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Indymedia helped \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Link offered \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t WikiLeaks endorsed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t October included \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Gapper said \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy protested \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Feds ordered \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t HSBC filed \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Rome masked \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy began \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Norway began \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t June included \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Cardiff set \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Progress suggested \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Vancouver added \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Conan launched \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Occupy influenced \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t FBI offered \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t FBI used \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t FBI withheld \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t FBI refused \t Tense=Past|VerbForm=Fin\n",
      "past_tense \t Shapiro filed \t Tense=Past|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Occupy Wall Street uses \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Rolling Jubilee claims \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Noam Chomsky argues \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Rolling Jubilee reports \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Information Act requests \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "sing_3rd_pres_fin \t Jodi Dean argues \t Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n"
     ]
    }
   ],
   "source": [
    "# Loop over each Span object in the list 'results'\n",
    "for result in morph_results:\n",
    "    \n",
    "    # Print out the the name of the pattern rule, a tabulator character, and the matching Span.\n",
    "    # Finally, print another tabulator character, followed by the morphological features of the\n",
    "    # last Token in the match (a verb).\n",
    "    print(nlp.vocab[result.label].text, '\\t', result, '\\t', result[-1].morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `past_tense` pattern can match objects based on a single morphological feature, although most matches share another morphological feature, namely a finite form of the verb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining matches in context using concordances\n",
    "\n",
    "We can examine matches in their context of occurrence using *concordances*. In corpus linguistics, concordances are often understood as lines of text that show a match in its context of occurrence.\n",
    "\n",
    "These concordance lines can help the analyst to understand the context in which a particular token or structure occurs, and to develop further hypotheses.\n",
    "\n",
    "To create concordance lines using spaCy, let's start by importing the Printer class from wasabi, which is a small [Python library](https://pypi.org/project/wasabi/) that spaCy uses for colouring and formatting messages. We will use wasabi to highlight the matches in the concordance lines.\n",
    "\n",
    "We first initialise a *Printer* object, which we then assign under the variable `match`. Next, we test the *Printer* object by printing some text in red colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;1mHello world!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import the Printer class from wasabi\n",
    "from wasabi import Printer\n",
    "\n",
    "# Initialise a Printer object; assign the object under the variable 'match'\n",
    "match = Printer()\n",
    "\n",
    "# Use the Printer to print out some text in red colour\n",
    "match.text(\"Hello world!\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed to loop over the results returned by the *Matcher* object `morph_matcher`. As we learned above, the results consist of *Span* objects in a list, which are stored under the variable `morph_results`.\n",
    "\n",
    "We loop over items in this list and use the `enumerate()` function to keep track of their count. We also provide the argument `start` with the value 1 to the `enumerate()` function to start counting from the number 1.\n",
    "\n",
    "During the loop, we refer to this count using the variable `i` and to the *Span* object as `result`. The number under `i` is incremented with every *Span* object.\n",
    "\n",
    "We then print out the following output for each *Span* object in the list `morph_results`:\n",
    "\n",
    " 1. `i`: The number of the item in the list.\n",
    " 2. `doc[result.start - 7: result.start]`: A slice of the *Doc* object stored under the variable `doc`, which we searched for matches. As usual, we define a slice using brackets and separate the start and end of a slice using a colon. We take a slice that begins 7 *Tokens* before the start of the match (`result.start - 7`), and terminates at the start of the match `result.start`.\n",
    " 3. `match.text(result, color=\"red\", no_print=True)`: The matching *Span* object, rendered using the wasabi *Printer* object `match` in red colour. We also set the argument `no_print` to `True` to prevent wasabi from printing the output on a new line.\n",
    " 4. `doc[result.end: result.end + 7]`: Another slice of the *Doc* object stored under the variable `doc`. Here we take a slice that begins at the end of the match `result.end` and terminates 7 *Tokens* after the end of the match (`result.end + 7`).\n",
    " \n",
    "Essentially, we use the indices available under `start` and `end` attributes of each *Span* to retrieve the linguistic context in which the *Span* occurs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 unity among the \"99%\".The \u001b[38;5;1mCommunity Environmental Legal Defense Fund released\u001b[0m a model community bill of rights,\n",
      "2 raid was chaotic and violent, but \u001b[38;5;1mOakland Police Chief Howard Jordan expressed\u001b[0m his pleasure concerning the operation because neither\n",
      "3 process.In March 2012, former \u001b[38;5;1mU.S. Vice President Al Gore called\u001b[0m on activists to \"occupy democracy\"\n",
      "4 few demands. On 12 October 2011 \u001b[38;5;1mLos Angeles City Council became\u001b[0m one of the first governmental bodies in\n",
      "5 by bullhorn, after reviewing it, \u001b[38;5;1mJudge Jed S. Rakoff sided\u001b[0m with plaintiffs, saying, \"a\n",
      "6 other countries.\"\n",
      "Canada— \u001b[38;5;1mFinance Minister Jim Flaherty expressed\u001b[0m sympathy with the protests, stating \"\n",
      "7 of that.\"\n",
      "India— \u001b[38;5;1mPrime Minister Manmohan Singh described\u001b[0m the protests as \"a warning for\n",
      "8 of governance\".\n",
      "Iran— \u001b[38;5;1mSupreme Leader Ayatollah Khamenei voiced\u001b[0m his support for the Occupy Movement saying\n",
      "9 —On 21 October 2011, former \u001b[38;5;1mPrime Minister Gordon Brown said\u001b[0m the protests were about fairness. \"\n",
      "10 Abraham Foxman, national director of the \u001b[38;5;1mAnti-Defamation League stated\u001b[0m that \"it's not surprising that\n",
      "11 . The Direct Action Working Group of \u001b[38;5;1mOccupy Wall Street endorsed\u001b[0m diversity of tactics from the earliest days\n",
      "12 march across the Brooklyn Bridge. The \u001b[38;5;1mNew York Times reported\u001b[0m that more than 700 arrests were made\n",
      "13 A. Myerson, a media coordinator for \u001b[38;5;1mOccupy Wall Street said\u001b[0m , \"The cops watched and did\n",
      "14 on 18 November 2011, campus police \u001b[38;5;1mLieutenant John Pike used\u001b[0m pepper spray on seated students. The\n",
      "15 Economic Forum. On 17 March, \u001b[38;5;1mOccupy Wall Street attempted\u001b[0m to mark six months of the movement\n",
      "16 clock until 23 July 2013, when \u001b[38;5;1mMayor Charlie Hales ordered\u001b[0m the removal of the vigil and associated\n",
      "17 The Roman Catholic church Santi Marcellino e \u001b[38;5;1mPietro al Laterano received\u001b[0m extensive damage, including a statue of\n",
      "18 an environmentalist protest against plans to replace \u001b[38;5;1mTaksim Gezi Park developed\u001b[0m into wider anti-government demonstrations.\n",
      "19 Executive Director Alison Bethel McKenzie of the \u001b[38;5;1mInternational Press Institute commented\u001b[0m : \"It is completely unacceptable to\n",
      "20 of the occupation.\n",
      "\n",
      "Brazil— \u001b[38;5;1mPresident Dilma Rousseff said\u001b[0m , \"We agree with some of\n",
      "21 . On Saturday 26 November 2011, \u001b[38;5;1mEdinburgh City Council set\u001b[0m a worldwide precedent by voting in favour\n",
      "22 Occupy Edinburgh.\n",
      "United States— \u001b[38;5;1mPresident Barack Obama spoke\u001b[0m in support of the movement, but\n",
      "23 City, Portland, Oakland, and \u001b[38;5;1mNew York City sent\u001b[0m in police to crack down on the\n",
      "24 removed by police.\n",
      "Venezuela— \u001b[38;5;1mPresident Hugo Chávez condemned\u001b[0m the \"horrible repression\" of the\n",
      "25 In January 2012, members of the \u001b[38;5;1mAmerican Dialect Society voted\u001b[0m with an overwhelming majority for \"Occupy\n",
      "26 instability. It formed part of what \u001b[38;5;1mManfred Steger called\u001b[0m the \"global justice movement\".The\n",
      "27 Washington Post, the movement, which \u001b[38;5;1mCornel West described\u001b[0m as a \"democratic awakening\",\n",
      "28 Nothing' first emerged.\" The \u001b[38;5;1mHuffington Post noted\u001b[0m that \"During one incident in March\n",
      "29 financial crisis. Adbusters co-founder \u001b[38;5;1mKalle Lasn registered\u001b[0m the OccupyWallStreet.org web address on 9 June\n",
      "30 the inspirations for the movement was the \u001b[38;5;1mDemocracy Village set\u001b[0m up in 2010, outside the British\n",
      "31 Hood tax planned for 29 October. \u001b[38;5;1mNaomi Wolf argued\u001b[0m that the impression created by much of\n",
      "32 Some commentators such as David Graeber and \u001b[38;5;1mJudith Butler criticized\u001b[0m the idea that the movement must have\n",
      "33 .\"In late May 2011, sociologist \u001b[38;5;1mManuel Castells congratulated\u001b[0m Spanish occupiers for the fact that not\n",
      "34 female protestors. In early October, \u001b[38;5;1mNaomi Klein congratulated\u001b[0m New York occupiers for their commitment to\n",
      "35 wished to stay. Rick Hampton for \u001b[38;5;1mUSA Today said\u001b[0m the vast majority of occupy members have\n",
      "36 the global movement in December 2011, \u001b[38;5;1mAnthony Barnett said\u001b[0m its nonviolence remained an immense strength.\n",
      "37 the Occupy Wall Street Movement, but \u001b[38;5;1mKanye West justified\u001b[0m his appearance as helping give power back\n",
      "38 Yoko Ono, Mark Ruffalo, and \u001b[38;5;1mMichael Moore tweeted\u001b[0m and showed their support.\n",
      "Many\n",
      "39 .\n",
      "\n",
      "The WikiLeaks endorsed news site \u001b[38;5;1mWikiLeaks Central began\u001b[0m promoting the idea of a \"US\n",
      "40 , and the American WikiLeaks Central writer \u001b[38;5;1mAlexa O'Brien modeled\u001b[0m the concept after the Day of Rages\n",
      "41 a forcible eviction. Financial Times editor \u001b[38;5;1mRichard Lambert suggested\u001b[0m that the shift to confrontational tactics by\n",
      "42 of the movement, Financial Times journalist \u001b[38;5;1mShannon Bond found\u001b[0m that issues of concern included: \"\n",
      "43 18 months. On 22 December The \u001b[38;5;1mWashington Post reported\u001b[0m that some of the cities which had\n",
      "44 .\n",
      "\n",
      "On 2 January 2012, \u001b[38;5;1mOccupy Nigeria began\u001b[0m , sparked by Nigeria's President Goodluck\n",
      "45 shutting down whole cities. On 16 \u001b[38;5;1mJanuary Jonathan responded\u001b[0m by announcing he would bring prices back\n",
      "46 relief to the New York area since \u001b[38;5;1mHurricane Sandy hit\u001b[0m , Occupy London's Occupy Economics group\n",
      "47 April 2016, hundreds of supporters of \u001b[38;5;1mBernie Sanders protested\u001b[0m outside of CNN's Headquarters in Los\n",
      "48 hiatus in activism on location, the \u001b[38;5;1mOccupy Movement organized\u001b[0m the Occupy ICE phase in order to\n",
      "49 .On August 19, 2018, \u001b[38;5;1mOccupy Kalamazoo began\u001b[0m an encampment in Bronson Park to address\n",
      "50 -occupying multiple sites since.\n",
      " \u001b[38;5;1mOccupy Sydney had\u001b[0m an ongoing occupation in Martin Place since\n",
      "51 Klárov\" in Prague was started. \u001b[38;5;1mPirate Party participated\u001b[0m in the occupation. Police dissolved the\n",
      "52 \", a permanent occupation of the \u001b[38;5;1mUnited Nations controlled\u001b[0m buffer zone in the centre of the\n",
      "53 of the European Central Bank, and \u001b[38;5;1mOccupy Berlin established\u001b[0m a protest camp at St. Mary's\n",
      "54 . On 13 August 2012, the \u001b[38;5;1mHigh Court ruled\u001b[0m that the protesters must leave the occupied\n",
      "55 Cork, Limerick and Galway. The \u001b[38;5;1mIrish Times described\u001b[0m the movement in the following terms:\n",
      "56 protest, many of the catchphrases of \u001b[38;5;1mOccupy Seoul contained\u001b[0m anti-government or anti-American\n",
      "57 of the observers has argued that \" \u001b[38;5;1mSouth Korea overcame\u001b[0m the 2008 financial crisis relatively well and\n",
      "58 riots in 2009. The 15- \u001b[38;5;1mM Movement drew\u001b[0m inspiration from 2011 revolutions in Tunisia,\n",
      "59 Wales. On 8 January 2012, \u001b[38;5;1mLancaster Police arrested\u001b[0m four members of Occupy Lancaster who were\n",
      "60 \".\n",
      "\n",
      "In Northern Ireland, \u001b[38;5;1mOccupy Belfast initiated\u001b[0m its protest outside the offices of Invest\n",
      "61 Invest NI on 21 October 2011. \u001b[38;5;1mOccupy Belfast took\u001b[0m residence at Writer's Square, in\n",
      "62 place in the near future.\n",
      " \u001b[38;5;1mOccupy Coleraine took\u001b[0m over the University of Ulster Common Room\n",
      "63 the Occupy movement worldwide. Protesters from \u001b[38;5;1mOccupy Glasgow set\u001b[0m up in the civic George Square on\n",
      "64 the January/February 2012 issue, \u001b[38;5;1mFrancis Fukuyama argued\u001b[0m that the Occupy movement was not as\n",
      "65 In early December 2011, business magnate \u001b[38;5;1mRichard Branson said\u001b[0m the movement is a \"good start\n",
      "66 difference.On 15 December 2011, \u001b[38;5;1mJesse Jackson said\u001b[0m that Jesus Christ, Gandhi, and\n",
      "67 .On 10 November 2011, The \u001b[38;5;1mDaily Telegraph reported\u001b[0m that the word \"occupy\" had\n",
      "68 \n",
      "\n",
      "On 27 December 2011, the \u001b[38;5;1mFinancial Times argued\u001b[0m that the movement had had a global\n",
      "69 .\" Also in November 2011, \u001b[38;5;1mPaul Mason said\u001b[0m that the Occupy movement had started to\n",
      "70 part of the political discourse and The \u001b[38;5;1mAtlantic Magazine declared\u001b[0m \"The Triumph of Occupy Wall Street\n",
      "71 of Financial Stability at the Bank of \u001b[38;5;1mEngland stated\u001b[0m that the protesters were right to criticise\n",
      "72 2010, students across the University of \u001b[38;5;1mCalifornia occupied\u001b[0m campus buildings in protest against budget cuts\n",
      "73 some journalists and commentators the camping in \u001b[38;5;1mSpain marked\u001b[0m the start of the global occupy movement\n",
      "74 additional attention when the internet hacker group \u001b[38;5;1mAnonymous encouraged\u001b[0m its followers to take part in the\n",
      "75 the top 400 income earners in the \u001b[38;5;1mU.S. saw\u001b[0m their income increase 392% and their\n",
      "76 7 October 2011, Kalle Lasn of \u001b[38;5;1mAdbusters said\u001b[0m that, in the early stages,\n",
      "77 not have clear demands was false. \u001b[38;5;1mWolf argued\u001b[0m that they did have clear demands including\n",
      "78 , and Meetup to coordinate events. \u001b[38;5;1mIndymedia helped\u001b[0m the movement with communications, saying there\n",
      "79 The progressive provider May First/People \u001b[38;5;1mLink offered\u001b[0m cost-free memberships for dozens of\n",
      "80 presidential candidates over others.\n",
      "\n",
      "The \u001b[38;5;1mWikiLeaks endorsed\u001b[0m news site WikiLeaks Central began promoting the\n",
      "81 . A list of events for 15 \u001b[38;5;1mOctober included\u001b[0m 951 cities in 82 countries. On\n",
      "82 FT, offered a different view. \u001b[38;5;1mGapper said\u001b[0m that it may be advantageous that the\n",
      "83 to one. In late January, \u001b[38;5;1mOccupy protested\u001b[0m at the World Economic Forum. On\n",
      "84 concerns'. On 25 June, \u001b[38;5;1mFeds ordered\u001b[0m the protestors to vacate government environs or\n",
      "85 fact that the protesters were peaceful, \u001b[38;5;1mHSBC filed\u001b[0m a lawsuit for their eviction. On\n",
      "86 Italian cities the same day. In \u001b[38;5;1mRome masked\u001b[0m and hooded militants wearing makeshift body armor\n",
      "87 Kelantan with Occupy Kota Bharu.\n",
      "\n",
      " \u001b[38;5;1mOccupy began\u001b[0m in Mexico City on 11 October 2011\n",
      "88 Nigeria.\n",
      "\n",
      "The Occupy movement in \u001b[38;5;1mNorway began\u001b[0m on 15 October with protests in Oslo\n",
      "89 government demonstrations. Demands issued on 4 \u001b[38;5;1mJune included\u001b[0m \n",
      "\n",
      "the end of police brutality,\n",
      "90 demonstrations outside Cardiff magistrates court. Occupy \u001b[38;5;1mCardiff set\u001b[0m up a new camp in the city\n",
      "91 for the think tank Center for American \u001b[38;5;1mProgress suggested\u001b[0m that the Occupy movement has succeeded in\n",
      "92 in July 2012, the City of \u001b[38;5;1mVancouver added\u001b[0m the word to its list of reserve\n",
      "93 In December 2012, the Television show \u001b[38;5;1mConan launched\u001b[0m a contest called \"Occupy Conan\"\n",
      "94 President Joe Biden, have suggested that \u001b[38;5;1mOccupy influenced\u001b[0m the President's January 2012 State of\n",
      "95 collected by corporate security, and the \u001b[38;5;1mFBI offered\u001b[0m to bank officials its plans to prevent\n",
      "96 Zions Bank about planned protests. The \u001b[38;5;1mFBI used\u001b[0m informants to infiltrate and monitor protests;\n",
      "97 with private corporate security officials. The \u001b[38;5;1mFBI withheld\u001b[0m documents requested under the FOIA citing the\n",
      "98 suppressed sniper rifles\". When the \u001b[38;5;1mFBI refused\u001b[0m the request, Shapiro filed a federal\n",
      "99 When the FBI refused the request, \u001b[38;5;1mShapiro filed\u001b[0m a federal complaint in Washington, D.C.\n",
      "100 join. In New York City, \u001b[38;5;1mOccupy Wall Street uses\u001b[0m what is called a progressive stack,\n",
      "101 off. As of September 2014, \u001b[38;5;1mRolling Jubilee claims\u001b[0m to have cancelled more than $15\n",
      "102 million in private student loan debt. \u001b[38;5;1mNoam Chomsky argues\u001b[0m that the movement \"spontaneously created something\n",
      "103 \". As of April 2015, \u001b[38;5;1mRolling Jubilee reports\u001b[0m it has cleared nearly $32 million\n",
      "104 in December 2012 pursuant to Freedom of \u001b[38;5;1mInformation Act requests\u001b[0m by the Partnership for Civil Justice Fund\n",
      "105 the Occupy movement, American political philosopher \u001b[38;5;1mJodi Dean argues\u001b[0m that the focus on autonomy, leaderlessness\n"
     ]
    }
   ],
   "source": [
    "# Loop over the matches in 'morph_results' and keep count of items\n",
    "for i, result in enumerate(morph_results, start=1):\n",
    "    \n",
    "    # Print following information for each match\n",
    "    print(i,   # Item number being looped over\n",
    "          doc[result.start - 7: result.start],   # The slice of the Doc preceding the match\n",
    "          match.text(result, color=\"red\", no_print=True),   # The match, rendered in red colour using wasabi\n",
    "          doc[result.end: result.end + 7])    # The slice of the Doc following the match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a set of concordance lines showing the matches in their context of occurrence.\n",
    "\n",
    "In some cases, the preceding or following *Tokens* consist of line breaks indicating a paragraph break, which causes the output to jump a row or two."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
